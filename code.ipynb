{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitenvvenv95402843946341c58083e1f593d38050",
   "display_name": "Python 3.8.1 64-bit ('env': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tarfile \n",
    "import urllib\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\" \n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\") \n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_housing_data(housing_path=HOUSING_PATH):    \n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ocean proximity is a categorical attribute.\n",
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describe method to show summary of numerical attributes.\n",
    "housing.describe()\n",
    "#The count of total_bedrooms is 20,433 not 20640.Some districts are missing this attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another quick way to get a feel of the data you are dealing with is to plot a histogram for each numerical attribute. \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "housing.hist(bins=50, figsize=(20,15)) \n",
    "plt.show()\n",
    "#If you observe median_income, they are scaled to 15 for higher values and 0.5 to lower values\n",
    "#Median age and median_income are also capped.Ml algorithms may learn that those attributes will never go beyong that limit. Collect proper labels for the districts or remove those districts\n",
    "#Histograms are tail-heavy, bit harder for ML algorithms to detect patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a test set\n",
    "import numpy as np \n",
    "def split_train_test(data, test_ratio):\n",
    "      shuffled_indices = np.random.permutation(len(data))\n",
    "      test_set_size = int(len(data) * test_ratio)\n",
    "      test_indices = shuffled_indices[:test_set_size] \n",
    "      train_indices = shuffled_indices[test_set_size:]\n",
    "      return data.iloc[train_indices], data.iloc[test_indices] \n",
    "\n",
    "train_set, test_set = split_train_test(housing, 0.2) \n",
    "len(train_set)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median income is a very important attribute to predict median housing prices. pd.cut() function is used to create an income category with five categories( 1 to 5)\n",
    "\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],                               labels=[1, 2, 3, 4, 5]) \n",
    "housing[\"income_cat\"].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stratified sampling\n",
    "#With stratified sampling, the researcher divides the population into separate groups, called strata. Then, a probability sample (often a simple random sample ) is drawn from each group.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) \n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):    \n",
    "    strat_train_set = housing.loc[train_index] \n",
    "    strat_test_set = housing.loc[test_index] \n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove income_cat attribute so that data is back to its original state\n",
    "for set_ in (strat_train_set, strat_test_set):    \n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the data to gain Insights. Let’s create a copy so that you can play with it without harming the training set\n",
    "housing = strat_train_set.copy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing geographical data\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard to see any particular pattern. Setting the alpha option to 0.1\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let’s look at the housing prices. The radius of each circle represents the district’s population (option s), and the color represents the price (option c). We will use a predefined color map (option cmap) called jet, which ranges from blue (low values) to red (high prices):\n",
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "        c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True, )\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking for correlations\n",
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False) \n",
    "# the median house value tends to go up when the median income goes up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to check correlation\n",
    "from pandas.plotting import scatter_matrix\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",              \"housing_median_age\"] \n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The most promising attribute to predict the median house value is the median income, so let’s zoom in on their correlation scatterplot \n",
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",             alpha=0.1)\n",
    "#the correlation is indeed very strong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experimenting with Attribute Combinations \n",
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"] \n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"] \n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]\n",
    "corr_matrix = housing.corr()  \n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
    "# houses with a lower bedroom/room ratio tend to be more expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the Data for Machine Learning Algorithms \n",
    "#separate the predictors and the labels\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) \n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "# ML algorithms cannot work with missing features, so let’s create a few functions to take care of them\n",
    "#1. Get rid of the corresponding districts. 2. Get rid of the whole attribute. 3. Set the values to some value (zero, the mean, the median, etc.). \n",
    "#housing.dropna(subset=[\"total_bedrooms\"])    # option 1 housing.drop(\"total_bedrooms\", axis=1)       # option 2\n",
    "# median = housing[\"total_bedrooms\"].median()  # option 3 housing[\"total_bedrooms\"].fillna(median, inplace=True) \n",
    "#I choose option3\n",
    "median = housing[\"total_bedrooms\"].median()  # option 3 housing[\"total_bedrooms\"].fillna(median, inplace=True) \n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " imputer.statistics_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " housing_num.median().values\n",
    " #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you can use this “trained” imputer to transform the training set by replacing missing values with the learned medians\n",
    "X = imputer.transform(housing_num) \n",
    "#\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing_num.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Text and Categorical Attributes\n",
    "#Lets look at text attributes\n",
    "\n",
    "housing_cat = housing[[\"ocean_proximity\"]]  \n",
    "housing_cat.head(10)\n",
    "#There is no arbitrary text. So this attribute is categorical attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding for this categorical attribute\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder() \n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ordinal_encoder.categories_ \n",
    " #One issue is the ML algorithms will assume that two nearby values are more similar than two distinct values. Good-> bad,avg,good.Not for our data. To fix this have a binary attribute per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " housing_cat_1hot.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.categories_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Transformers\n",
    "#transformer that adds the combined attributes\n",
    "\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "     def __init__(self, add_bedrooms_per_room = True):\n",
    "          self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "     def fit(self, X, y=None):\n",
    "          return self\n",
    "     def transform(self, X):\n",
    "          rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "          population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "          if self.add_bedrooms_per_room:\n",
    "               bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "               return np.c_[X, rooms_per_household, population_per_household,                         bedrooms_per_room]\n",
    "          else:\n",
    "               return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False) \n",
    "housing_extra_attribs = attr_adder.transform(housing.values)   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "#to get all attributes to have the same scale, we choose standardization\n",
    "#Transformation Pipelines - To execute data transformation steps in right order\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('attribs_adder', CombinedAttributesAdder()),                  ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To handle both numerical and catogorical in a single column\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attribs),\n",
    "            (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "        ])\n",
    "housing_prepared = full_pipeline.fit_transform(housing) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select and Train a model on Training set\n",
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression() \n",
    "lin_reg.fit(housing_prepared, housing_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try few instances of linear regression on training set\n",
    "some_data = housing.iloc[:5] \n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels)) \n",
    "#Predictions are not accurate with lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE Error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse  \n",
    "#most districts’ median_hous ing_values range between $120,000 and $265,000, so a typical prediction error of $68,628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor() \n",
    "tree_reg.fit(housing_prepared, housing_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The erros is 0. Its evaluate using cross-Validation\n",
    "#Using K-fold cross validation feature\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look at the results\n",
    "def display_scores(scores):\n",
    "      print(\"Scores:\", scores)\n",
    "      print(\"Mean:\", scores.mean())\n",
    "      print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)\n",
    "#Worse than Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores for Linear Regression\n",
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,scoring=\"neg_mean_squared_error\", cv=10)                                   \n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(forest_reg, housing_prepared, housing_labels,                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_scores(forest_rmse_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}